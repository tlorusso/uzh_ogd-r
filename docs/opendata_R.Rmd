---
title: "Opendata & R"
subtitle: ""
author: "Thomas Lo Russo"
date: "Universität Zürich </br> 21.11.2018"
output:
  xaringan::moon_reader:
    css: lib/zh.css
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
---
class: middle center

## About me

Research Associate 

Official Statistics & Open Government Data 

Canton of Zurich

#### [open.zh.ch](open.zh.ch/)

#### [statistik.zh.ch](statistik.zh.ch/)

`r icon::fa("twitter")`[@thlorusso](https://twitter.com/thlorusso)

???
Dank den ID für Einladung.

Wir produzieren ein Grossteil unserer Statistiken, der Visualisierungen die wir veröffentlichen bis hin zu ganzen Publikationen mit R. 

Seit Anfang 2018 bin ich quasi zweigeteilt und darf als Teil der Fach- und Koordinationsstelle Open Government Data am Ausbau des Angebots offener Behördendaten mitarbeiten. 

In dieser Veranstaltungsreihe geht es um offene Daten für Öffentlichkeit und Forschung. In meinem Referat wird es jedoch nicht nur um offene Daten gehen, sondern darum welchen Mehrwert das Arbeiten mit offenen Daten UND offener Software wie etwa R gleichzeitig bieten. Natürlich - wenn immer möglich. 

---
# The challenges of data aquisition

- getting data is a critical step in most research 

- sometimes one of the most difficult and time-consuming steps 

- even when data is accessible not granted that it is easy to find 

- frustrating format variabilities & compatibility issues 

Not only hindering academic research, but also the development of innovative data-driven products & services.

???

Welche Herausforderungen haben Sie zu meistern, wenn Sie als Forschende, als Datenjournalisten oder als Privatpersonen eine Frage haben, die sie anhand von strukturierer, hochqualitativer Informationen beantwortet haben möchten? 

Die müssen sich diese beschaffen. 

Aber... es ist nicht immer ganz einfach. Sie können sich glücklich schätzen, wenn Sie in einem Projekt arbeiten in dem man Ihnen die Daten schon fix - fertig aufbereitet zur Verfügung stellen kann. Doch ist dies wahrscheinlich nicht die Regel. Wir kriegen beim Statistischen Amt tagtäglich Anfragen zu den unterschiedlichsten Themen und wissen um die Schwierigkeiten bei der Datenbeschaffung.

---

# Open Data to the rescue

__Open Data can contribute to making data aquisition much less painful__

- machine readable, freely accessible & published in open formats with open license  

- searchable on open data portals (e.g. [opendata.swiss](https://opendata.swiss/de/) / [data.europa.eu](http://data.europa.eu/) / [opentransportdata.swiss](https://opentransportdata.swiss/en/) / [opendata.cern.ch](http://opendata.cern.ch/))

--

Also, there are many ongoing efforts to make it easier to retrieve data directly from (open) repositories with the same tools that are used for analysis. Initatives such as __rOpenSci__ contribute heavily to this ("open tools for open science").

In the case of __R__ → growing number of (open) data-packages and API-wrappers.

<img src="https://avatars3.githubusercontent.com/u/1200269?v=3&s=280" alt="drawing" width="7%"/>

https://ropensci.org/


???

Offene Daten können Abhilfe schaffen. Den offene Daten erfüllen idR eine Reihe von Kriterien, die einem das Leben erleichtern. Sie kommen in maschinenlesbarer Form daher - nicht in Form unstrukturierter pdf Dateien aus denen sie beispielsweise Tabellen mühsam herauskopieren müssen. Sie kommen in offenen Formaten daher, als zum Beispiel einer csv oder json Datei - sie benötigen also keine spezifische, propietäre SW um diese zu verarbeiten. Und sie stehen unter einer offenen Lizenz, die Klarheit schafft was die Nutzung der Daten angeht und es ihnen erlaubt die Daten für ihre Zwecke zu nutzen. Dies ist kein zu vernachlässigender Aspekt: es gibt Daten die frei verfügbar sind im Netz, die sie sich beschaffen können, obwohl sie ggf. gegen Nutzungsbedingungen verstossen, wenn sie diese für Forschungszwecke benutzen.

Offene Daten - insbesondere die die durch den Staat oder durch grössere Unternehmen oder Forschungsinistitutionen pubiliziert werden sind zudem auf Portalen wie opendata.swiss suchbar, die den selben standard anwenden (DCAT) und so eine Art Ökosystem darstellen.

Es gibt Bemühungen , Daten direkt in die Tools bringen, welche Forschende und Entwickler nutzen. Einmal suchen , dann mit demselben Code wiederkehrend dasselbe tun. Das bedeuted, eine Analyse zu einem späteren Zeitpunkt mit aktualisierten Daten ganz einfach repetieren zu können.


---
# What is `r icon::fa("r-project")`?

- programming language  
- open source  
- runs on multiple platforms  


The R package - ecosystem comprehends a myriad of packages that extend the functionality of the R language. They range from data-manipulation, data-collection and visualization to modelling, GIS as well as many domain specific applictions.


__Field Guide to the R Ecosystem__
https://fg2re.sellorm.com/whatisr.html



???

R ist eine open source programmiersprache. Man kann sie interaktiv ausführen, oder auch skripte ablegen die dann ein interpreter ausführt - ähnlich wie bei ruby oder python. 

R hebt sich von diesen sprachen jedoch punkto haupt-einsatzgebiet ab. Obwohl R immer breiter wird in der anwendung, war es ursprünglich ein open-source nachfolger der statistik-sprache S. Somit ist R in erster linie eine programmiersprache für statistischen gebrauch - und dementsprechend weitverbreitet an den universitäten in - statistik-programmen oder data-science lehrgängen weltweit. Für die öffentliche Statistik ist R prädestiniert - ich war diesen Herbst an einer Konferenz zur Nutzung von R in der öff. Statistik : R ist das TOol der wahl.
---
class: inverse, center, middle

<img src="lib/rknife.png" alt="drawing" width="50%"/>

???
R - ursprünglich statsitik-prgrammiersprache für datenanylse und modellierung ist mittlerweile ein echt vielfältiges werkzeug - ähnlich einem Sackmesser.Daten manipulation, modellierung von der Regression zu statistischem lernen, aber auch Daten erheen im netz (web scraping / crawling). Und in gewissen Dingen ist R ziemlich exzellent - zum beisipel wenn es darum geht, die eigenen Resultate direkt aus R heraus in ein publikationsreifes Gefäss einzubetten.

Was ist damit gemeint? 

---
With R you can create fully reproducible documents in various formats, books, presentations, blogposts or even build web-applications that let others explore data interactively.

<center><img src="lib/R.png" alt="drawing" width="30%"/></center>

???
Mit R können Sie reproduzierbare Dokumente in unterschiedlichster Form generieren. Ganze Bücher oder Dissertationen, sie könnemit R eine Webseite generieren und im Stile eines Datenblogs laufends aus R heraus neue Posts publizieren, sie können Web-Applikationen bauen die andere ihre Daten und Resultate interaktiv durchforsten lassen. Sie sehen - die Möglichkeiten sind schier unbegrenzt - und das mit frei verfügbarer Software.


---

# Open Data & R to the rescue

- __R__ (and similar open source software) lowers the barriers and costs to make data analysis __repeatable and reproducible__.

- __Open Data__ ensures that everyone can access the same information for free (ideally, in a well structured manner)

--

## Democratization of data & tools for analysis

--


However, it is not always possible to use open data (sensitive data, privacy & security reasons) and open source software (special formats).

But whenever it is possible, their combination allows for __reproducibilty__, __repeatability__ as well as __collaboration on unprecedentend scale__

???
Rekapitulieren wir hier kurz : R (und ähnliche oss) senken kosten und barrieren um datenanalyse repetier- und reproduzierbar zu machen. 

Offene Daten ermöglichen, dass jeder freien zugriff auf dieselben, gut strukturierten, informationen hat. 

Dies kommt einer demokratisierung von information in form von daten und der werkzeuge für die analyse gleich. 

Natürlich : nicht immer möglich offene Daten zu nutzen - Einzeldaten, Gesundheitsdaten : Daten die aus datenschutz- oder sicherheitsgründen nicht offen sein können. Auch bei den Formaten, wen man es mit speziellen Datenstrukturen zu tun hat, die mit proprietärer Software ausgwertet werden müssen.

Aber wenn es möglich ist : erlaubt ihnen diese Kombination nie da gewesene r & r und auch zusammenarbeit über organisationsgrenzen hinweg, ohne sich dabei darum kümmern zu müssen wer zugriffsberechtigt ist oder wer eine lizenz von software x hat.

---
class: centre, middle

<center><a href="https://twitter.com/RTreb/status/1063717277001023490"><img src="lib/tweet.PNG" alt="tweet" height="50%"/></a></center>

---
class: inverse, center, middle

# R & Open Government Data 

### Showcase : Real Time Data-Service of Vote Results in the Canton Zurich

???

Nun haben sie viel grundsätzliches gehört. Über zu einem Beispiel mit offenen Daten des Kantons Zürich. Als Politologie-Absolvent habe ich eines gewählt dass mit besonders am Herzen liegt. Das stat amt ist auch die kantonale Wahl- und Abstimmungszentrale. Die Resultate aus den Gemeinden fliessen am Abstimmungssontag bei uns zusammen, wir plausibilisieren diese und publizieren die Resultate laufend. Über unseren Echtzeitdaten-Service können unseren Datenstrom direkt anzapfen und den Auszählstand in Echzeit abrufen oder in eine Applikation oder einen Live-ticker einbetten. 


---
The Canton of Zurich provides a web service for real time results on voting sundays.
https://opendata.swiss/de/dataset/echtzeitdaten-am-abstimmungstag

```{r,message=FALSE,warning=FALSE}
library(sf)
library(tidyverse)

# get json via webservice, dataset-description : https://opendata.swiss/de/dataset/echtzeitdaten-am-abstimmungstag
data <- jsonlite::fromJSON("http://www.wahlen.zh.ch/abstimmungen/2016_09_25/viewer_download.php")

# transform nested list into an R-friendly dataframe
data <- data %>% 
  map_dfr(bind_rows) %>% 
  unnest(VORLAGEN)

```

???
Der Service ist auf opendata.swiss beschrieben. Für jeden Abstimmungstermin gibt es ein neues Datum / neuen Link. Ich kann das json via R abfragen und es dann in eine R-freundliche Datenstruktur bringen.

---
Some data preparation...
```{r,message=FALSE,warning=FALSE, message=FALSE, dpi=100, fig.height=2}
#short labels for each vote topic
data$VORLAGE_NAME <- factor(data$VORLAGE_NAME, labels = c("Grüne Wirtschaft", "AHV Plus", "NDG", "Bezahlbare Kinderbetreuung"))

data <-data %>% mutate_at(vars(JA_STIMMEN_ABSOLUT,NEIN_STIMMEN_ABSOLUT,JA_PROZENT,STIMMBETEILIGUNG),as.numeric)

#aggregate results on municipality level
data <-data %>% 
  group_by(BFS,VORLAGE_NAME) %>% 
  summarize(ja_anteil=round(sum(JA_STIMMEN_ABSOLUT,na.rm=T)/sum(JA_STIMMEN_ABSOLUT+NEIN_STIMMEN_ABSOLUT,na.rm=T)*100,1))
```

???
Um mit analyse & visualisierung loslegen zu können versehe ich die Abstimmungen noch mit Kurzbezeichnungen und rechne die Resultate auf die Gemeindeebene hoch. Der Webservice liefert diese auf Wahlkreisebene. 

---

Let's take a glimpse at the distribution of yes-shares across municipalities and voting topics.
.pull-left[
```{r, dpi=120, warning=FALSE, message=FALSE}
plot<-ggplot(data, aes(x=ja_anteil)) + 
              geom_histogram(fill="steelblue")+
              facet_wrap(~VORLAGE_NAME)+
              scale_x_continuous(limits = c(0, 100),breaks=seq(0,100,25))
```
]
--

.pull-right[

```{r, warnings=FALSE, dpi=90,message=FALSE,echo=FALSE}
plot
```

]

???
Nun sind wir soweit : wir können die Verteilung der Ja-Anteile anschauen. 

---

.pull-left[

By adding geodata (municipality borders), we can visualize the results on a map.

```{r,message=FALSE,warning=FALSE}
# get municipality-borders shapefile
downloader::download("http://www.web.statistik.zh.ch/cms_basiskarten/gen_Gemeinde_2017/GEN_A4_GEMEINDEN_SEEN_2017_F.zip", dest="dataset.zip", mode="wb")

unzip("dataset.zip")

gemeinden <- sf::read_sf("GEN_A4_GEMEINDEN_SEEN_2017_F" ,stringsAsFactors = FALSE) %>% select(BFS,BEZIRK)

#join geodata to the vote result dataframe
mapdata <- inner_join(gemeinden,data, by=c("BFS")) 

#map displaying yes-shares per municpality
map <- ggplot(mapdata)+
  geom_sf(aes(fill=ja_anteil),colour="white")+
  facet_wrap(~VORLAGE_NAME)
```
]

--

.pull-right[

```{r, dpi=120}
map
```

]

??? 
In dem wir uns noch Geodaten mit den Gemeindegrenzen dazuholen können wir die ja-anteile auch auf einer Karte anzeigen.

---

.pull-left[

```{r,message=FALSE,warning=FALSE, dpi=125}

mapnew <- map+
              coord_sf(datum = NA)+ #<<
              labs(fill="Ja (in %)")+#<<
              theme_void()+ #<<
              scale_fill_gradient2(midpoint=50)+ #<<
              guides(fill = guide_colourbar(barwidth = 0.5, barheight = 10)) #<<

```
]

--

.pull-right[

```{r,echo=FALSE, dpi=120}
mapnew
```

]

---

```{r}

glimpse(mapdata)

```

In R, we can store the actual data as well as the needed geo-information in the same tabular dataframe. The [sf-package](https://r-spatial.github.io/sf/) makes this happen.

---
Let's add some data to try to explain the results of a specific vote.
```{r}
# https://opendata.swiss/de/dataset/bevolkerung-pers -> population
bev <- read.csv("http://www.web.statistik.zh.ch/ogd/data/KANTON_ZUERICH_133.csv", sep=";", encoding="UTF8") %>%
  select(BFS = `ï..BFS_NR`, einwohner=INDIKATOR_VALUE,INDIKATOR_JAHR,GEBIET_NAME) %>% 
  dplyr::filter(INDIKATOR_JAHR==2017 & BFS != 0)

# https://opendata.swiss/de/dataset/nrw-wahleranteil-sp -> social democrats vote share
sp <- read.csv("http://www.web.statistik.zh.ch/ogd/data/KANTON_ZUERICH_124.csv", sep=";", encoding="UTF8") %>%
  select(BFS = `ï..BFS_NR`, sp_anteil=INDIKATOR_VALUE,INDIKATOR_JAHR) %>% 
  dplyr::filter(INDIKATOR_JAHR==2015 & BFS != 0)

# join to vote-results
plotdata <- mapdata %>% 
            filter(VORLAGE_NAME=="Bezahlbare Kinderbetreuung") %>% 
            left_join(sp, by=c("BFS")) %>% 
            left_join(bev, by=c("BFS")) %>% 
            mutate_at(vars(sp_anteil,einwohner),as.numeric) 
```

???
Wen wir nun eine Erklärung für die unterschiedlich hohe Zustimmung zu einer Vorlage suchen möchten, können wir uns noch weitere Daten von opendata.swiss holen. Hier laden wir Einwohnerzahlen und SP-Wähleranteile herunter. Ich fügen diese mit den Abstimmungsdaten zusammen.


---

.pull-left[
```{r,warnings=FALSE,message=FALSE}
# devtools::install_github("statistikZH/statR")
library(statR)

plot <- ggplot(plotdata, aes(sp_anteil,ja_anteil, size=einwohner/1000))+
            geom_point(colour="steelblue",alpha=0.8)+
            theme_stat()+
            guides(fill="FALSE")+
            labs(title="Bezahlbare Kinderbetreuung",
                 subtitle="Zustimmung zur VI bezahlbare Kinderbetreuung vs SP-Wähleranteil (NRW 2015)")

```
]

--

.pull-right[
```{r,warnings=FALSE, dpi=120,message=FALSE}
plot
```
]

???
Sie sehen - auf Gemeindeebene gibt es einen Zusammenhang zwischen Ja zur Initative für bezahlbare Kinderbetreeung und SP-Wähleranteil - war zu erwarten, war ein Links anliegen. 


---
class: inverse, middle, center


## Every step, from data-retrieval to the final visualizations, is repeatable AND reproducible

--

`r icon::fa("arrow-down")`
# TRUST


???
Sie können diese Präsentation und die Grafiken darin selbst erstellen in dem Sie einfach den Code nehmen. Sie müssen nichts händisch herunterladen und die Daten noch selber in eine Form bringen, welche es ihnen erlaubt diese auf Fehler zu prüfen. Aber was bringt das? Es erhöht das Vertrauen. Sie können sehen auf welchem Weg ich zum Ziel gekommen bin. An den Schlüssen, die ich daraus ziehe, an denen könnten sie zweifeln. 

---

## How does this work?

- With [RMarkdown](https://rmarkdown.rstudio.com/), narrative text and code are part of the same document. We can weave elegantly formated output, such as this very presentation, from it.

- By recurring to freely available (open) data sources the data is integrated just by linking to it (stable URL / API).

---
class: inverse, middle,center

# Interactive Graphics & 
# Web Applications with R

---
With just one line of code, we can visualize the yes-shares on an interactive map.

```{r,eval=FALSE}
library(mapview)

mapview(plotdata,zcol="ja_anteil")
```

<center>
```{r,echo=FALSE}
library(mapview)

mapview(plotdata,zcol="ja_anteil")
```
</center>

---
# Building a Web-App with R

<img src="lib/shiny.jpg" alt="drawing" width="10%"/>

With Shiny, we can build an R powered Web-Application nurtured by the data on opendata.swiss. Shiny Apps let other people run your R-Code interactively without having to code themselfes.

https://statistikzh.shinyapps.io/zhvote/

--
- The app is automatically updated, as soon as a new vote date is listed, via the opendata.swiss [CKAN Action API](https://handbook.opendata.swiss/support/api.html)
--

- No need to update by hand __before__ votation sundays
--

- Real time data stream __on__ votation sundays
--

- No web development skills required

???

Some basic html / css skills nice to have : customizing! The nice thing with R is that if you know R , it lets you do things as this (building web apps)

---
# A further example

A Shiny App that allows to compare social walfare rates:

https://statistikzh.shinyapps.io/swr_zh/

---
# Conclusion

To use R and | or open Data for analysis helps in terms of:

#### Reproducibilty
#### Repeatability
#### Much simpler collaboration 

R is a very versatile tool. It lets you do a broad variety of things that go far beyond the scope of a statistical programming language.

---
class: middle, center

## Upcoming : Zurich R User Group Meetup

### R programming with Martin Mächler

Wednsday, 5. December 2018

https://www.meetup.com/de-DE/Zurich-R-User-Group/

![rusergroup](https://secure.meetupstatic.com/photos/event/c/e/3/0/600_466012784.jpeg)

---
### Are you new to R?

[Getting Started with R](https://support.rstudio.com/hc/en-us/articles/201141096-Getting-Started-with-R)

## Resources : Open Data & R

[Data of the Canton of Zurich on opendata.swiss](https://opendata.swiss/de/organization/kanton-zuerich)

[rOpenSci-TaskView on how to obtain, parse, create and share OpenData](https://github.com/ropensci/opendata)

[Open Data in R and rOpenSci](https://nceas.github.io/oss-lessons/open-data-in-r/open-data-in-R.html)

[The Antarctic/Southern Ocean rOpenSci community](https://ropensci.org/blog/2018/11/13/antarctic/)



